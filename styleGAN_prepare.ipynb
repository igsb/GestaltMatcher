{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f968cf7a-024f-4b91-bb18-25d8cb8be929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lib.datasets.utils import load_synds_list, load_deep_gestalt_encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8dc7bc-4fb8-4539-bffb-f13a71b2b847",
   "metadata": {},
   "source": [
    " python train.py --outdir=training-runs --data=..\\..\\data\\GestaltMatcherDB\\GMDB_syndrome --gpus=1\n",
    " --cfg=auto --cond=1 --metrics=none  --resume=training-runs\\00016-GMDB_syndrome-cond-auto1\\training-runs\\00016-GMDB_syndrome-cond-auto1 --snap=25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed609b98-9e7f-4dd2-ac69-81fb869d9fc8",
   "metadata": {},
   "source": [
    "python train.py --outdir=training-runs --data=..\\..\\data\\GAN\\ --gpus=1 --cfg=auto --cond=1 --met\n",
    "rics=none  --snap=25 --mirror=1 --aug=ada --dry-run --augpipe=gmdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "27454762-2fbd-4c4c-9592-7e9cca2f2316",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('./gmdb_metadata/gmdb_syndromes_v1.tsv', sep='\\t')\n",
    "df = pd.read_csv('../data/GestaltMatcherDB/v1.0.1/gmdb_metadata_v1.0.1/gmdb_syndromes_v1.0.1.csv', sep=',')\n",
    "synd_ids = df.syndrome_id.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d8ea35-acc5-43b4-b090-278b6035b906",
   "metadata": {},
   "source": [
    "# Prepare Training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "232bf1df-780f-4886-9dee-089ea2eb23b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('./gmdb_metadata/gmdb_syndromes_v1.tsv', sep='\\t')\n",
    "df = pd.read_csv('../data/GestaltMatcherDB/v1.0.1/gmdb_metadata_v1.0.1/gmdb_syndromes_v1.0.1.csv', sep=',')\n",
    "synd_ids = df.syndrome_id.values\n",
    "work_path = '../synthesis/stylegan2-ada-pytorch/'\n",
    "input_path = os.path.join('../data/GestaltMatcherDB/v1.0.1/gmdb_crops_v1.0.1/')\n",
    "output_path = '../data/GAN/GMDB_syndrome_original_images_v1.0.1'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6d3e7e99-d92d-4ea0-8009-37fd133c1deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image_ids'] = df.apply(lambda x: [int(i.strip(' ').strip('\\n')) for i in x['image_ids'][1:-1].split(' ') if i != ''], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0cd6d055-5293-4c1c-b7e6-9c9877a5e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../data/GAN/GMDB_syndrome_crops_v1.0.1'\n",
    "input_path = '../data/GestaltMatcherDB/v1.0.1/gmdb_crops_v1.0.1/'\n",
    "for idx, row in df.iterrows():\n",
    "    synd_id = row['syndrome_id']\n",
    "    image_ids = row['image_ids']\n",
    "    synd_output_path = os.path.join(output_path, str(synd_id))\n",
    "    if not os.path.exists(synd_output_path):\n",
    "        os.makedirs(synd_output_path)\n",
    "    for input_image_id in image_ids:\n",
    "        input_file = os.path.join(input_path, '{}_crop_square.jpg'.format(input_image_id))\n",
    "        output_file = os.path.join(synd_output_path, '{}.jpg'.format(input_image_id))\n",
    "        shutil.copyfile(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a545b13-150d-41fc-91cb-3e8d4a519d9c",
   "metadata": {},
   "source": [
    " python dataset_tool.py --source=..\\..\\data\\GAN\\GMDB_syndrome_original_images_v1.0.1 --dest=..\\..\n",
    "\\data\\GAN\\train_synd_images_v1.0.1 --width=128 --height=128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "15ef17db-8bfa-4858-9254-ae2e5a2b0cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/GestaltMatcherDB/v1.0.1/gmdb_metadata_v1.0.1/gmdb_frequent_gallery_images_v1.0.1.csv', sep=',')\n",
    "image_ids = df.image_id.values\n",
    "output_prefix = '../data/GAN/GMDB_syndrome_crops_v1.0.1'\n",
    "input_prefix = '../data/GestaltMatcherDB/v1.0.1/gmdb_crops_v1.0.1/'\n",
    "if not os.path.exists(output_prefix):\n",
    "    os.mkdir(output_prefix)\n",
    "all_labels = []\n",
    "count = 0\n",
    "count_str = 0\n",
    "for idx, row in df.iterrows():\n",
    "    image_id = row['image_id']\n",
    "    label = str(row['label'])\n",
    "    input_image = os.path.join(input_prefix, '{}_crop_square.jpg'.format(image_id))\n",
    "    if count == 1000:\n",
    "        count_str += 1\n",
    "        count = 0\n",
    "    count_str_dir = '0'*(5-len(str(count_str))) + str(count_str)\n",
    "    out_dir = os.path.join(output_prefix, count_str_dir)\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "\n",
    "    img = Image.open(input_image).convert('L')\n",
    "    img = img.resize((128, 128))\n",
    "    filename = 'img' + '0'*(8-len(str(image_id))) + str(image_id) + '.png'\n",
    "    output_image = os.path.join(out_dir, filename)\n",
    "    img.save(output_image, format='png')\n",
    "    \n",
    "    all_labels.append([count_str_dir + '/' + filename, int(label)])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "82bc4fd4-4417-469e-b441-5f57b508d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = {'labels': all_labels}\n",
    "with open(output_prefix+ '\\dataset.json', 'w') as outfile:\n",
    "    json.dump(json_string, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7670632-18b8-4771-a453-41c7c4826f7b",
   "metadata": {},
   "source": [
    "# Save into syndrome folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e2fee4-6a74-4d89-b5d9-5dbd3b90b730",
   "metadata": {},
   "source": [
    "# Generate images from StyleGan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "160a287f-a20f-4eee-8040-922103c9a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/GestaltMatcherDB/v1.0.1/gmdb_metadata_v1.0.1/gmdb_syndromes_v1.0.1.csv', sep=',')\n",
    "synd_ids = df.syndrome_id.values\n",
    "synd_num_of_images = {row['syndrome_id']: row['num_of_images'] for idx, row in df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3f9dd506-6a5b-4c62-8ad8-4a2ad6802ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_path = '../synthesis/stylegan2-ada-pytorch/'\n",
    "#model_path = os.path.join(work_path, 'training-runs/00016-GMDB_syndrome-cond-auto1/network-snapshot-000140.pkl')\n",
    "model_path = os.path.join(work_path, 'training-runs/00022-GMDB_syndrome_crops_v1.0-cond-mirror-auto1-ada-gmdb/network-snapshot-000300.pkl')\n",
    "output_path = os.path.join(work_path, 'GMDB_train_synd_v1.0.1_gmdb_ada')\n",
    "py_file = os.path.join(work_path, 'generate.py')\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "count = 0\n",
    "for idx, synd_id in enumerate(synd_ids):\n",
    "    num_of_images = synd_num_of_images[idx]\n",
    "    synd_output_path = os.path.join(output_path, str(synd_id))\n",
    "    if not os.path.exists(synd_output_path):\n",
    "        os.makedirs(synd_output_path)\n",
    "    seeds = '{}-{}'.format(count, count+num_of_images-1)\n",
    "    count = count+num_of_images\n",
    "    cmd = ' '.join(['python', py_file, '--class={}'.format(idx), '--network={}'.format(model_path),\n",
    "                   '--outdir={}'.format(synd_output_path), '--seeds={}'.format(seeds)])\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3f1909f-7e02-46c0-8223-daf6c83210ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ../synthesis/stylegan2-ada-pytorch/generate.py --class=0 --network=../synthesis/stylegan2-ada-pytorch/training-runs/00016-GMDB_syndrome-cond-auto1/network-snapshot-000120.pkl --outdir=../synthesis/stylegan2-ada-pytorch/GMDB_train_synd\\0 --seeds=0-243\n"
     ]
    }
   ],
   "source": [
    "print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2126579b-e9d4-42c4-a81d-ada852b52d3a",
   "metadata": {},
   "source": [
    "# Crop and encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79b12fe6-04f1-47eb-b178-9e1414e2e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_path = '../synthesis/stylegan2-ada-pytorch/'\n",
    "input_path = os.path.join(work_path, 'GMDB_train_synd')\n",
    "output_path = '../data/GMDB_gan_original_images'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "for idx, synd_id in enumerate(synd_ids):\n",
    "    synd_input_path = os.path.join(input_path, str(synd_id))\n",
    "    input_images = os.listdir(synd_input_path)\n",
    "    for input_image in input_images:\n",
    "        input_file = os.path.join(synd_input_path, input_image)\n",
    "        image_id = int(input_image[4:-4])\n",
    "        output_file = os.path.join(output_path, '{}.png'.format(image_id))\n",
    "        shutil.copyfile(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44330cca-a0cc-47a1-b13d-2f192a493979",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('gmdb_metadata/gmdb_train_images_v1.csv')\n",
    "val_df = pd.read_csv('gmdb_metadata/gmdb_val_images_v1.csv')\n",
    "test_df = pd.read_csv('gmdb_metadata/gmdb_test_images_v1.csv')\n",
    "synd_train_dict = {}\n",
    "synd_val_dict = {}\n",
    "synd_test_dict = {}\n",
    "for i, j  in train_df['label'].value_counts().items():\n",
    "    synd_train_dict[i] = j\n",
    "\n",
    "for i, j  in val_df['label'].value_counts().items():\n",
    "    synd_val_dict[i] = j\n",
    "\n",
    "for i, j  in test_df['label'].value_counts().items():\n",
    "    synd_test_dict[i] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3966c3be-c785-4dd2-b173-bc4b65c26039",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_ids = np.array([])\n",
    "train_labels = np.array([])\n",
    "val_image_ids = np.array([])\n",
    "val_labels = np.array([])\n",
    "test_image_ids = np.array([])\n",
    "test_labels = np.array([])\n",
    "count = 0\n",
    "synd_list = list(synd_train_dict.keys())\n",
    "synd_list.sort()\n",
    "for idx, synd_id in enumerate(synd_list):\n",
    "    num_train_images = synd_train_dict[synd_id]\n",
    "    num_val_images = synd_val_dict[synd_id]\n",
    "    num_test_images = synd_test_dict[synd_id]\n",
    "    train_image_ids = np.append(train_image_ids, np.arange(count, count+num_train_images))\n",
    "    train_labels = np.append(train_labels, np.array([synd_id]*num_train_images))\n",
    "    count += num_train_images\n",
    "    val_image_ids = np.append(val_image_ids, np.arange(count, count+num_val_images))\n",
    "    val_labels = np.append(val_labels, np.array([synd_id]*num_val_images))\n",
    "    count += num_val_images\n",
    "    test_image_ids = np.append(test_image_ids, np.arange(count, count+num_test_images))\n",
    "    test_labels = np.append(test_labels, np.array([synd_id]*num_test_images))\n",
    "    count += num_test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "15c12218-997a-41d8-b5f7-d196fbd6c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_out_df = pd.DataFrame({'image_id': train_image_ids, 'label': train_labels, 'subject': train_image_ids})\n",
    "train_out_df.to_csv('../data/gmdb_gan_train_images_v1.csv', index=False)\n",
    "val_out_df = pd.DataFrame({'image_id': val_image_ids, 'label': val_labels, 'subject': val_image_ids})\n",
    "val_out_df.to_csv('../data/gmdb_gan_val_images_v1.csv', index=False)\n",
    "test_out_df = pd.DataFrame({'image_id': test_image_ids, 'label': test_labels, 'subject': test_image_ids})\n",
    "val_out_df.to_csv('../data/gmdb_gan_test_images_v1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52109a30-a093-4669-9632-0ba3c8512b31",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d883fbbb-ef17-40c0-98cb-0e1e66cc478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('gmdb_metadata/gmdb_train_images_v1.csv')\n",
    "val_df = pd.read_csv('gmdb_metadata/gmdb_val_images_v1.csv')\n",
    "test_df = pd.read_csv('gmdb_metadata/gmdb_test_images_v1.csv')\n",
    "labels = test_df.label.values\n",
    "synd_list = load_synds_list('lookup_table.txt')\n",
    "\n",
    "embeddings = []\n",
    "image_ids = []\n",
    "control_subject_ids = []\n",
    "for image_id in test_df.image_id.values:\n",
    "    encoding = load_deep_gestalt_encodings('gmdb_gan_dg_encodings\\{}.csv'.format(image_id), synd_list)\n",
    "    embeddings.append(encoding['image_softmax_ranks'][str(image_id)])\n",
    "    image_ids.append(image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8619269a-641e-4399-b44e-3f915bbabced",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ranks = []\n",
    "for i in range(len(image_ids)):\n",
    "    ranks = embeddings[i]\n",
    "    #print(labels[i])\n",
    "    image_ranks.append(np.where(ranks == labels[i])[0][0])\n",
    "image_ranks = np.array(image_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d4931ee2-65af-43f7-81b1-5dfb9cc1cadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 acc: 14.17%\n",
      "Top-5 acc: 29.17%\n",
      "Top-10 acc: 37.78%\n",
      "Top-30 acc: 54.17%\n"
     ]
    }
   ],
   "source": [
    "for i in [1, 5, 10, 30]:\n",
    "    acc = sum(image_ranks < i)/len(image_ranks)*100\n",
    "    print('Top-{} acc: {:.2f}%'.format(i, acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "618aa7ad-9180-407c-a6d3-b3439e8cd40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 acc: 55.42%\n",
      "Top-5 acc: 77.09%\n",
      "Top-10 acc: 83.74%\n",
      "Top-30 acc: 93.60%\n"
     ]
    }
   ],
   "source": [
    "#val_out_df.to_csv('../data/gmdb_gan_test_images_v1.csv', index=False)\n",
    "test_df = pd.read_csv('../data/gmdb_gan_test_images_v1.csv').astype('int')\n",
    "labels = test_df.label.values\n",
    "synd_list = load_synds_list('lookup_table.txt')\n",
    "\n",
    "embeddings = []\n",
    "image_ids = []\n",
    "control_subject_ids = []\n",
    "for image_id in test_df.image_id.values:\n",
    "    encoding = load_deep_gestalt_encodings('gan_dg_encodings\\{}.csv'.format(image_id), synd_list)\n",
    "    embeddings.append(encoding['image_softmax_ranks'][str(image_id)])\n",
    "    image_ids.append(image_id)\n",
    "image_ranks = []\n",
    "for i in range(len(image_ids)):\n",
    "    ranks = embeddings[i]\n",
    "    #print(labels[i])\n",
    "    image_ranks.append(np.where(ranks == labels[i])[0][0])\n",
    "image_ranks = np.array(image_ranks)\n",
    "for i in [1, 5, 10, 30]:\n",
    "    acc = sum(image_ranks < i)/len(image_ranks)*100\n",
    "    print('Top-{} acc: {:.2f}%'.format(i, acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ab76bfad-3f49-4081-9d0c-7b970b421992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 acc: 37.22%\n",
      "Top-5 acc: 59.72%\n",
      "Top-10 acc: 69.44%\n",
      "Top-30 acc: 84.17%\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('gmdb_metadata/gmdb_train_images_v1.csv')\n",
    "val_df = pd.read_csv('gmdb_metadata/gmdb_val_images_v1.csv')\n",
    "test_df = pd.read_csv('gmdb_metadata/gmdb_test_images_v1.csv')\n",
    "labels = test_df.label.values\n",
    "synd_list = load_synds_list('lookup_table.txt')\n",
    "\n",
    "embeddings = []\n",
    "image_ids = []\n",
    "control_subject_ids = []\n",
    "for image_id in test_df.image_id.values:\n",
    "    encoding = load_deep_gestalt_encodings('gmdb_dg_encodings\\{}.csv'.format(image_id), synd_list)\n",
    "    embeddings.append(encoding['image_softmax_ranks'][str(image_id)])\n",
    "    image_ids.append(image_id)\n",
    "image_ranks = []\n",
    "for i in range(len(image_ids)):\n",
    "    ranks = embeddings[i]\n",
    "    #print(labels[i])\n",
    "    image_ranks.append(np.where(ranks == labels[i])[0][0])\n",
    "image_ranks = np.array(image_ranks)\n",
    "for i in [1, 5, 10, 30]:\n",
    "    acc = sum(image_ranks < i)/len(image_ranks)*100\n",
    "    print('Top-{} acc: {:.2f}%'.format(i, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "192a88a6-f786-4b26-8ef3-09729ffd9aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 acc: 19.95%\n",
      "Top-5 acc: 34.98%\n",
      "Top-10 acc: 47.04%\n",
      "Top-30 acc: 64.78%\n"
     ]
    }
   ],
   "source": [
    "#val_out_df.to_csv('../data/gmdb_gan_test_images_v1.csv', index=False)\n",
    "test_df = pd.read_csv('../data/gmdb_gan_test_images_v1.csv').astype('int')\n",
    "labels = test_df.label.values\n",
    "synd_list = load_synds_list('lookup_table.txt')\n",
    "\n",
    "embeddings = []\n",
    "image_ids = []\n",
    "control_subject_ids = []\n",
    "for image_id in test_df.image_id.values:\n",
    "    encoding = load_deep_gestalt_encodings('gan_images_dg_encodings\\{}.csv'.format(image_id), synd_list)\n",
    "    embeddings.append(encoding['image_softmax_ranks'][str(image_id)])\n",
    "    image_ids.append(image_id)\n",
    "image_ranks = []\n",
    "for i in range(len(image_ids)):\n",
    "    ranks = embeddings[i]\n",
    "    #print(labels[i])\n",
    "    image_ranks.append(np.where(ranks == labels[i])[0][0])\n",
    "image_ranks = np.array(image_ranks)\n",
    "for i in [1, 5, 10, 30]:\n",
    "    acc = sum(image_ranks < i)/len(image_ranks)*100\n",
    "    print('Top-{} acc: {:.2f}%'.format(i, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babb1d64-d1ec-4f6c-96c4-18f4ccc40d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train",
   "language": "python",
   "name": "train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
